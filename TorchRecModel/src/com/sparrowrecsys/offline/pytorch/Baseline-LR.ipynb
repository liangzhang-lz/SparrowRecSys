{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use LR as baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get training and test sample, remove unused columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/home/leon/Documents/SparrowRecSys/src/main/resources/webroot/sampledata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = folder_path + \"/Pytorch_data/trainingSamples.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = folder_path + \"/Pytorch_data/testSamples.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.read_csv(training_path, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(test_path, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>label</th>\n",
       "      <th>releaseYear</th>\n",
       "      <th>movieGenre1</th>\n",
       "      <th>movieGenre2</th>\n",
       "      <th>movieGenre3</th>\n",
       "      <th>movieRatingCount</th>\n",
       "      <th>...</th>\n",
       "      <th>userGenre3</th>\n",
       "      <th>userGenre4</th>\n",
       "      <th>userGenre5</th>\n",
       "      <th>scaledReleaseYear</th>\n",
       "      <th>scaledmovieRatingCount</th>\n",
       "      <th>scaledmovieAvgRating</th>\n",
       "      <th>scaledmovieRatingStddev</th>\n",
       "      <th>scaleduserRatingCount</th>\n",
       "      <th>scaleduserAvgRating</th>\n",
       "      <th>scaleduserRatingStddev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>593</td>\n",
       "      <td>10096</td>\n",
       "      <td>4.0</td>\n",
       "      <td>954365552</td>\n",
       "      <td>1</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>13692.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.936777</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.449735</td>\n",
       "      <td>0.030612</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.279874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>832</td>\n",
       "      <td>10351</td>\n",
       "      <td>3.0</td>\n",
       "      <td>851791379</td>\n",
       "      <td>0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3052.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>0.985916</td>\n",
       "      <td>0.208758</td>\n",
       "      <td>0.649306</td>\n",
       "      <td>0.486773</td>\n",
       "      <td>0.112245</td>\n",
       "      <td>0.726667</td>\n",
       "      <td>0.229560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85</td>\n",
       "      <td>10351</td>\n",
       "      <td>3.0</td>\n",
       "      <td>851791395</td>\n",
       "      <td>0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>592.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.040438</td>\n",
       "      <td>0.690972</td>\n",
       "      <td>0.502645</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.713333</td>\n",
       "      <td>0.229560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>588</td>\n",
       "      <td>10351</td>\n",
       "      <td>5.0</td>\n",
       "      <td>851792205</td>\n",
       "      <td>1</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>8980.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>0.929577</td>\n",
       "      <td>0.614369</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.486773</td>\n",
       "      <td>0.224490</td>\n",
       "      <td>0.675555</td>\n",
       "      <td>0.207547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>370</td>\n",
       "      <td>1090</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1117852491</td>\n",
       "      <td>0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3087.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.957747</td>\n",
       "      <td>0.211153</td>\n",
       "      <td>0.482639</td>\n",
       "      <td>0.555555</td>\n",
       "      <td>0.030612</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.204403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  userId  rating   timestamp  label  releaseYear  movieGenre1  \\\n",
       "0      593   10096     4.0   954365552      1       1991.0           13   \n",
       "1      832   10351     3.0   851791379      0       1996.0           13   \n",
       "2       85   10351     3.0   851791395      0       1995.0           11   \n",
       "3      588   10351     5.0   851792205      1       1992.0            3   \n",
       "4      370    1090     2.0  1117852491      0       1994.0            2   \n",
       "\n",
       "   movieGenre2  movieGenre3  movieRatingCount  ...  userGenre3  userGenre4  \\\n",
       "0            4           12           13692.0  ...          17          12   \n",
       "1           12            0            3052.0  ...           5          12   \n",
       "2            5            0             592.0  ...           5          12   \n",
       "3           15           18            8980.0  ...          12           5   \n",
       "4            7            0            3087.0  ...           0           0   \n",
       "\n",
       "   userGenre5  scaledReleaseYear  scaledmovieRatingCount  \\\n",
       "0           0           0.915493                0.936777   \n",
       "1          13           0.985916                0.208758   \n",
       "2          13           0.971831                0.040438   \n",
       "3          13           0.929577                0.614369   \n",
       "4           0           0.957747                0.211153   \n",
       "\n",
       "   scaledmovieAvgRating  scaledmovieRatingStddev  scaleduserRatingCount  \\\n",
       "0              0.906250                 0.449735               0.030612   \n",
       "1              0.649306                 0.486773               0.112245   \n",
       "2              0.690972                 0.502645               0.122449   \n",
       "3              0.729167                 0.486773               0.224490   \n",
       "4              0.482639                 0.555555               0.030612   \n",
       "\n",
       "   scaleduserAvgRating  scaleduserRatingStddev  \n",
       "0             0.688889                0.279874  \n",
       "1             0.726667                0.229560  \n",
       "2             0.713333                0.229560  \n",
       "3             0.675555                0.207547  \n",
       "4             0.200000                0.204403  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NaN items in 'userRatedMovie1' column, movieId starts from 1, so we can use 0 to do padding\n",
    "training_df.fillna(0, inplace=True)\n",
    "test_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns2Keep = ['userId', 'userGenre1', 'userGenre2',  'userGenre3','userGenre4', 'userGenre5', 'scaleduserRatingCount',\n",
    "       'scaleduserAvgRating', 'scaleduserRatingStddev', 'userRatedMovie1', 'movieId',  'movieGenre1', 'movieGenre2', 'movieGenre3', 'scaledReleaseYear', 'scaledmovieRatingCount', 'scaledmovieAvgRating',\n",
    "       'scaledmovieRatingStddev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_feature = training_df[columns2Keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_label = training_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature = test_df[columns2Keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_feature['userRatedMovie1'] = training_feature['userRatedMovie1'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature['userRatedMovie1'] = test_feature['userRatedMovie1'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> userId\n",
      "1 -> userGenre1\n",
      "2 -> userGenre2\n",
      "3 -> userGenre3\n",
      "4 -> userGenre4\n",
      "5 -> userGenre5\n",
      "6 -> scaleduserRatingCount\n",
      "7 -> scaleduserAvgRating\n",
      "8 -> scaleduserRatingStddev\n",
      "9 -> userRatedMovie1\n",
      "10 -> movieId\n",
      "11 -> movieGenre1\n",
      "12 -> movieGenre2\n",
      "13 -> movieGenre3\n",
      "14 -> scaledReleaseYear\n",
      "15 -> scaledmovieRatingCount\n",
      "16 -> scaledmovieAvgRating\n",
      "17 -> scaledmovieRatingStddev\n"
     ]
    }
   ],
   "source": [
    "for i, col_name in enumerate(training_feature.columns):\n",
    "    print(str(i) + \" -> \" + col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>userGenre1</th>\n",
       "      <th>userGenre2</th>\n",
       "      <th>userGenre3</th>\n",
       "      <th>userGenre4</th>\n",
       "      <th>userGenre5</th>\n",
       "      <th>scaleduserRatingCount</th>\n",
       "      <th>scaleduserAvgRating</th>\n",
       "      <th>scaleduserRatingStddev</th>\n",
       "      <th>userRatedMovie1</th>\n",
       "      <th>movieId</th>\n",
       "      <th>movieGenre1</th>\n",
       "      <th>movieGenre2</th>\n",
       "      <th>movieGenre3</th>\n",
       "      <th>scaledReleaseYear</th>\n",
       "      <th>scaledmovieRatingCount</th>\n",
       "      <th>scaledmovieAvgRating</th>\n",
       "      <th>scaledmovieRatingStddev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10096</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030612</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.279874</td>\n",
       "      <td>50</td>\n",
       "      <td>593</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.936777</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.449735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10351</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>0.112245</td>\n",
       "      <td>0.726667</td>\n",
       "      <td>0.229560</td>\n",
       "      <td>26</td>\n",
       "      <td>832</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.985916</td>\n",
       "      <td>0.208758</td>\n",
       "      <td>0.649306</td>\n",
       "      <td>0.486773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10351</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.713333</td>\n",
       "      <td>0.229560</td>\n",
       "      <td>26</td>\n",
       "      <td>85</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.040438</td>\n",
       "      <td>0.690972</td>\n",
       "      <td>0.502645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10351</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>0.224490</td>\n",
       "      <td>0.675555</td>\n",
       "      <td>0.207547</td>\n",
       "      <td>582</td>\n",
       "      <td>588</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>0.929577</td>\n",
       "      <td>0.614369</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.486773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1090</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030612</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.204403</td>\n",
       "      <td>0</td>\n",
       "      <td>370</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.957747</td>\n",
       "      <td>0.211153</td>\n",
       "      <td>0.482639</td>\n",
       "      <td>0.555555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84480</th>\n",
       "      <td>9515</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.684444</td>\n",
       "      <td>0.270440</td>\n",
       "      <td>153</td>\n",
       "      <td>485</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.196989</td>\n",
       "      <td>0.420139</td>\n",
       "      <td>0.529101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84481</th>\n",
       "      <td>9515</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.418367</td>\n",
       "      <td>0.668889</td>\n",
       "      <td>0.261006</td>\n",
       "      <td>153</td>\n",
       "      <td>720</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>0.985916</td>\n",
       "      <td>0.123298</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.550265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84482</th>\n",
       "      <td>9515</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.671111</td>\n",
       "      <td>0.257862</td>\n",
       "      <td>720</td>\n",
       "      <td>296</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>0.957747</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.518518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84483</th>\n",
       "      <td>9515</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.682222</td>\n",
       "      <td>0.261006</td>\n",
       "      <td>527</td>\n",
       "      <td>318</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.957747</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.380952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84484</th>\n",
       "      <td>9515</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0.459184</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.267296</td>\n",
       "      <td>318</td>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.699282</td>\n",
       "      <td>0.965278</td>\n",
       "      <td>0.396825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84485 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  userGenre1  userGenre2  userGenre3  userGenre4  userGenre5  \\\n",
       "0       10096          13          11          17          12           0   \n",
       "1       10351          11           7           5          12          13   \n",
       "2       10351          11           7           5          12          13   \n",
       "3       10351          11           7          12           5          13   \n",
       "4        1090           0           0           0           0           0   \n",
       "...       ...         ...         ...         ...         ...         ...   \n",
       "84480    9515           2          12          13           3           7   \n",
       "84481    9515           2          12          13           3           7   \n",
       "84482    9515           2          12          13           3           7   \n",
       "84483    9515           2          12          13           3           7   \n",
       "84484    9515           2          12          13           3          11   \n",
       "\n",
       "       scaleduserRatingCount  scaleduserAvgRating  scaleduserRatingStddev  \\\n",
       "0                   0.030612             0.688889                0.279874   \n",
       "1                   0.112245             0.726667                0.229560   \n",
       "2                   0.122449             0.713333                0.229560   \n",
       "3                   0.224490             0.675555                0.207547   \n",
       "4                   0.030612             0.200000                0.204403   \n",
       "...                      ...                  ...                     ...   \n",
       "84480               0.367347             0.684444                0.270440   \n",
       "84481               0.418367             0.668889                0.261006   \n",
       "84482               0.428571             0.671111                0.257862   \n",
       "84483               0.448980             0.682222                0.261006   \n",
       "84484               0.459184             0.688889                0.267296   \n",
       "\n",
       "       userRatedMovie1  movieId  movieGenre1  movieGenre2  movieGenre3  \\\n",
       "0                   50      593           13            4           12   \n",
       "1                   26      832           13           12            0   \n",
       "2                   26       85           11            5            0   \n",
       "3                  582      588            3           15           18   \n",
       "4                    0      370            2            7            0   \n",
       "...                ...      ...          ...          ...          ...   \n",
       "84480              153      485            2            3            7   \n",
       "84481              153      720            3           15            7   \n",
       "84482              720      296            7           13           11   \n",
       "84483              527      318           13           11            0   \n",
       "84484              318       50           13           17           12   \n",
       "\n",
       "       scaledReleaseYear  scaledmovieRatingCount  scaledmovieAvgRating  \\\n",
       "0               0.915493                0.936777              0.906250   \n",
       "1               0.985916                0.208758              0.649306   \n",
       "2               0.971831                0.040438              0.690972   \n",
       "3               0.929577                0.614369              0.729167   \n",
       "4               0.957747                0.211153              0.482639   \n",
       "...                  ...                     ...                   ...   \n",
       "84480           0.943662                0.196989              0.420139   \n",
       "84481           0.985916                0.123298              0.861111   \n",
       "84482           0.957747                1.000000              0.902778   \n",
       "84483           0.957747                0.945946              1.000000   \n",
       "84484           0.971831                0.699282              0.965278   \n",
       "\n",
       "       scaledmovieRatingStddev  \n",
       "0                     0.449735  \n",
       "1                     0.486773  \n",
       "2                     0.502645  \n",
       "3                     0.486773  \n",
       "4                     0.555555  \n",
       "...                        ...  \n",
       "84480                 0.529101  \n",
       "84481                 0.550265  \n",
       "84482                 0.518518  \n",
       "84483                 0.380952  \n",
       "84484                 0.396825  \n",
       "\n",
       "[84485 rows x 18 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSet and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_col = [0, 1, 2, 3, 4, 5, 9, 10, 11, 12, 13] # column_index of sparse features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_col_size = [30001, 20, 20, 20, 20, 20, 1001, 1001, 20, 20, 20] # number of classes per sparse_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_col = [6, 7, 8, 14, 15, 16, 17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ModelDataSet(Dataset):\n",
    "    # Retrieve an item in every call\n",
    "    def __init__(self, input_DF, label_DF, sparse_col, dense_col):\n",
    "        self.df = input_DF\n",
    "        \n",
    "        self.dense_df = input_DF.iloc[:, dense_col].astype(np.float32) \n",
    "        self.sparse_df = input_DF.iloc[:, sparse_col].astype('int64') \n",
    "        \n",
    "        self.label = label_DF.astype(np.float32) \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        sparse_feature = torch.tensor(self.sparse_df.iloc[idx])\n",
    "        dense_feature = torch.tensor(self.dense_df.iloc[idx])\n",
    "        label = torch.tensor(self.label.iloc[idx])\n",
    "        return {'Feature': (sparse_feature, dense_feature), 'Label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_dataset = ModelDataSet(training_feature, training_label, sparse_col, dense_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ModelDataSet(test_feature, test_label, sparse_col, dense_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(training_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define the FM module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LR(nn.Module):\n",
    "    def __init__(self, sparse_col_size, dense_col_size):\n",
    "        # sparse_col_size: list[int]\n",
    "        # dense_col_size: int\n",
    "        super().__init__()\n",
    "        self.sparse_col_size = sparse_col_size\n",
    "        self.dense_col_size = dense_col_size\n",
    "        \n",
    "        \n",
    "        # 1st order linear layer\n",
    "        fisrt_order_size = np.sum(sparse_col_size) + dense_col_size\n",
    "        self.linear_firstOrder = nn.Linear(fisrt_order_size, 1)\n",
    "        \n",
    "    def forward(self, sparse_feature, dense_feature):\n",
    "        if (len(sparse_feature.shape) == 1): # 1D tensor coverted to 2D tensor if batch_number == 1\n",
    "            sparse_feature = sparse_feature.view(1, -1)\n",
    "            dense_feature = dense_feature.view(1, -1)\n",
    "        \n",
    "        # convert sparse feature to oneHot and Embedding\n",
    "        one_hot_list =[]\n",
    "        for i in range(len(self.sparse_col_size)):\n",
    "            sparse_feature_input = sparse_feature[:, i] # batch x 1\n",
    "            class_size = self.sparse_col_size[i]\n",
    "            one_hot_vec = F.one_hot(sparse_feature_input, num_classes=class_size).squeeze(1) # batch x class_number\n",
    "            one_hot_list.append(one_hot_vec)\n",
    "        \n",
    "        one_hot_list.append(dense_feature)\n",
    "        \n",
    "        # Prepare input for 1st order layer, FM, deep layer\n",
    "        sparse_one_hot = torch.cat(one_hot_list, dim=1)   # B x (sum(one_hot)+10), 10 is the size of dense_embedding\n",
    "        # linear layer\n",
    "        linear_logit = self.linear_firstOrder(sparse_one_hot)\n",
    "        logit = linear_logit \n",
    "        return F.sigmoid(logit).view(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LR(sparse_col_size, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_Eval():\n",
    "    def __init__(self, model, loss_fn, optim, device, train_dataloader, test_dataloader):\n",
    "        self.device = device\n",
    "        self.model = model.to(self.device)\n",
    "        self.optim = optim\n",
    "        self.loss_fn = loss_fn\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.test_dataloader = test_dataloader\n",
    "        self.threashold = 0.5 # threashold for positive class\n",
    "        \n",
    "    def train(self, epochs):\n",
    "        self.model.train()\n",
    "        for epoch in range(epochs):\n",
    "            print(\"==========================================================\")\n",
    "            print(\"start training epoch: {}\".format(epoch+1))\n",
    "            loss_list = []\n",
    "            pred_list = []\n",
    "            label_list = []\n",
    "            \n",
    "            iteration = 1\n",
    "            for train_data in self.train_dataloader:\n",
    "                sparse_feature = train_data['Feature'][0].to(self.device)\n",
    "                dense_feature = train_data['Feature'][1].to(self.device)\n",
    "                label = train_data['Label'].to(self.device)\n",
    "                prediction = self.model(sparse_feature, dense_feature)\n",
    "                \n",
    "                pred_list.extend(prediction.tolist())\n",
    "                label_list.extend(label.tolist())\n",
    "                \n",
    "                cur_loss = self.loss_fn(prediction, label)\n",
    "                loss_list.append(cur_loss.item())\n",
    "                cur_loss.backward()\n",
    "                self.optim.step()\n",
    "                self.optim.zero_grad()\n",
    "                \n",
    "                # logging every 20 iteration\n",
    "                if iteration % 20 == 0:\n",
    "                    print(\"---------------------------------------------------------\")\n",
    "                    print(\"epoch {}/{}, cur_iteration is {}, logloss is {:.2f}\"\n",
    "                          .format(epoch+1, epochs, iteration, cur_loss.item()))\n",
    "                iteration += 1\n",
    "                \n",
    "            # validation every epoch\n",
    "            training_loss, training_accuracy, training_roc_score = self._getMetric(loss_list, pred_list, label_list)\n",
    "            print(\"==========================================================\")\n",
    "            print(\"Result of epoch {}\".format(epoch+1))\n",
    "            print(f\"training loss: {training_loss:.2f}, accuracy: {training_accuracy:.3f}, roc_score: {training_roc_score:.2f}\")\n",
    "            \n",
    "            test_loss, test_accuracy, test_roc_score = self.eval()\n",
    "            print(f\"test loss: {test_loss:.2f}, accuracy: {test_accuracy:.3f}, roc_score: {test_roc_score:.2f}\")\n",
    "            # summary.add_embedding(np.reshape(np.array(loss_list), (1, -1)), tag=\"loss_list\")\n",
    "            # summary.add_embedding(np.reshape(np.array(pred_list), (1, -1)), tag=\"pred_list\")\n",
    "            # summary.add_embedding(np.reshape(np.array(label_list), (1, -1)), tag=\"label_list\")\n",
    "            # summary.add_scalar(\"training_loss\", training_loss)\n",
    "            # summary.add_scalar(\"training_accuracy\", training_accuracy)\n",
    "            # summary.add_scalar(\"training_roc_score\", training_roc_score)\n",
    "    \n",
    "    def eval(self):\n",
    "        # return logloss, accuracy, roc_score\n",
    "        self.model.eval()\n",
    "        loss_list = []\n",
    "        pred_list = []\n",
    "        label_list = []\n",
    "        with torch.no_grad():\n",
    "            for test_data in self.test_dataloader:\n",
    "                sparse_feature = test_data['Feature'][0].to(self.device)\n",
    "                dense_feature = test_data['Feature'][1].to(self.device)\n",
    "                label = test_data['Label'].to(self.device)\n",
    "                prediction = self.model(sparse_feature, dense_feature)\n",
    "                cur_loss = self.loss_fn(prediction, label)\n",
    "                \n",
    "                loss_list.append(cur_loss.item())\n",
    "                pred_list.extend(prediction.tolist())\n",
    "                label_list.extend(label.tolist())\n",
    "        return self._getMetric(loss_list, pred_list, label_list)\n",
    "                \n",
    "    def _getMetric(self, loss_list, pred_list, label_list):\n",
    "        # return logloss, accuracy, roc_score        \n",
    "        # average logloss\n",
    "        avg_loss = np.mean(loss_list)\n",
    "        # roc_score\n",
    "        roc_score = roc_auc_score(label_list, pred_list)\n",
    "        # average accuracy\n",
    "        pred_class_list = list(map(lambda x: 1 if x >= self.threashold else 0, pred_list))\n",
    "        correct_count = 0\n",
    "        for p, l in zip(pred_class_list, label_list):\n",
    "            if p == l:\n",
    "                correct_count += 1\n",
    "        avg_accuracy = correct_count / len(label_list)\n",
    "        \n",
    "        return avg_loss, avg_accuracy, roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eval = Train_Eval(model, loss_fn, optimizer, dev, training_dataloader, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "start training epoch: 1\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 20, logloss is 0.68\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 40, logloss is 0.63\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 60, logloss is 0.67\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 80, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 100, logloss is 0.64\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 120, logloss is 0.61\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 140, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 160, logloss is 0.65\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 180, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 200, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 220, logloss is 0.69\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 240, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 260, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 280, logloss is 0.70\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 300, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 320, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 340, logloss is 0.61\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 360, logloss is 0.63\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 380, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 400, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 420, logloss is 0.65\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 440, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 460, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 480, logloss is 0.61\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 500, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 520, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 540, logloss is 0.67\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 560, logloss is 0.55\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 580, logloss is 0.66\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 600, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 620, logloss is 0.54\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 640, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 660, logloss is 0.61\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 680, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 700, logloss is 0.61\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 720, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 740, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 760, logloss is 0.61\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 780, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 800, logloss is 0.54\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 820, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 840, logloss is 0.59\n",
      "==========================================================\n",
      "Result of epoch 1\n",
      "training loss: 0.61, accuracy: 0.673, roc_score: 0.73\n",
      "test loss: 0.55, accuracy: 0.731, roc_score: 0.77\n",
      "==========================================================\n",
      "start training epoch: 2\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 20, logloss is 0.55\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 40, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 60, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 80, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 100, logloss is 0.65\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 120, logloss is 0.61\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 140, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 160, logloss is 0.53\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 180, logloss is 0.54\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 200, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 220, logloss is 0.54\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 240, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 260, logloss is 0.64\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 280, logloss is 0.55\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 300, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 320, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 340, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 360, logloss is 0.61\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 380, logloss is 0.53\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 400, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 420, logloss is 0.50\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 440, logloss is 0.55\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 460, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 480, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 500, logloss is 0.55\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 520, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 540, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 560, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 580, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 600, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 620, logloss is 0.55\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 640, logloss is 0.63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 660, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 680, logloss is 0.54\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 700, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 720, logloss is 0.61\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 740, logloss is 0.55\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 760, logloss is 0.65\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 780, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 800, logloss is 0.53\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 820, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 840, logloss is 0.59\n",
      "==========================================================\n",
      "Result of epoch 2\n",
      "training loss: 0.59, accuracy: 0.691, roc_score: 0.76\n",
      "test loss: 0.55, accuracy: 0.729, roc_score: 0.78\n",
      "==========================================================\n",
      "start training epoch: 3\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 20, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 40, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 60, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 80, logloss is 0.55\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 100, logloss is 0.51\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 120, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 140, logloss is 0.61\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 160, logloss is 0.61\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 180, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 200, logloss is 0.61\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 220, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 240, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 260, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 280, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 300, logloss is 0.52\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 320, logloss is 0.55\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 340, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 360, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 380, logloss is 0.66\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 400, logloss is 0.55\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 420, logloss is 0.53\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 440, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 460, logloss is 0.65\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 480, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 500, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 520, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 540, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 560, logloss is 0.61\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 580, logloss is 0.55\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 600, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 620, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 640, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 660, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 680, logloss is 0.61\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 700, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 720, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 740, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 760, logloss is 0.61\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 780, logloss is 0.54\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 800, logloss is 0.54\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 820, logloss is 0.55\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 840, logloss is 0.65\n",
      "==========================================================\n",
      "Result of epoch 3\n",
      "training loss: 0.58, accuracy: 0.694, roc_score: 0.76\n",
      "test loss: 0.54, accuracy: 0.730, roc_score: 0.78\n",
      "==========================================================\n",
      "start training epoch: 4\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 20, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 40, logloss is 0.55\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 60, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 80, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 100, logloss is 0.68\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 120, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 140, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 160, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 180, logloss is 0.64\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 200, logloss is 0.55\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 220, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 240, logloss is 0.52\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 260, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 280, logloss is 0.55\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 300, logloss is 0.53\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 320, logloss is 0.54\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 340, logloss is 0.55\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 360, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 380, logloss is 0.64\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 400, logloss is 0.56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 420, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 440, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 460, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 480, logloss is 0.63\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 500, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 520, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 540, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 560, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 580, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 600, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 620, logloss is 0.52\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 640, logloss is 0.61\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 660, logloss is 0.53\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 680, logloss is 0.55\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 700, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 720, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 740, logloss is 0.65\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 760, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 780, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 800, logloss is 0.55\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 820, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 840, logloss is 0.54\n",
      "==========================================================\n",
      "Result of epoch 4\n",
      "training loss: 0.58, accuracy: 0.694, roc_score: 0.76\n",
      "test loss: 0.53, accuracy: 0.739, roc_score: 0.78\n",
      "==========================================================\n",
      "start training epoch: 5\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 20, logloss is 0.63\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 40, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 60, logloss is 0.68\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 80, logloss is 0.54\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 100, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 120, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 140, logloss is 0.61\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 160, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 180, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 200, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 220, logloss is 0.52\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 240, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 260, logloss is 0.66\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 280, logloss is 0.53\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 300, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 320, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 340, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 360, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 380, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 400, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 420, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 440, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 460, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 480, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 500, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 520, logloss is 0.54\n"
     ]
    }
   ],
   "source": [
    "train_eval.train(EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of LR(\n",
       "  (linear_firstOrder): Linear(in_features=32170, out_features=1, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
