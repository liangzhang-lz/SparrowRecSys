{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get training and test sample, remove unused columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/home/leon/Documents/SparrowRecSys/src/main/resources/webroot/sampledata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = folder_path + \"/Pytorch_data/trainingSamples.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = folder_path + \"/Pytorch_data/testSamples.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.read_csv(training_path, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(test_path, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>label</th>\n",
       "      <th>releaseYear</th>\n",
       "      <th>movieGenre1</th>\n",
       "      <th>movieGenre2</th>\n",
       "      <th>movieGenre3</th>\n",
       "      <th>movieRatingCount</th>\n",
       "      <th>...</th>\n",
       "      <th>userGenre3</th>\n",
       "      <th>userGenre4</th>\n",
       "      <th>userGenre5</th>\n",
       "      <th>scaledReleaseYear</th>\n",
       "      <th>scaledmovieRatingCount</th>\n",
       "      <th>scaledmovieAvgRating</th>\n",
       "      <th>scaledmovieRatingStddev</th>\n",
       "      <th>scaleduserRatingCount</th>\n",
       "      <th>scaleduserAvgRating</th>\n",
       "      <th>scaleduserRatingStddev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>593</td>\n",
       "      <td>10096</td>\n",
       "      <td>4.0</td>\n",
       "      <td>954365552</td>\n",
       "      <td>1</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>13692.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.936777</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.449735</td>\n",
       "      <td>0.030612</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.279874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>832</td>\n",
       "      <td>10351</td>\n",
       "      <td>3.0</td>\n",
       "      <td>851791379</td>\n",
       "      <td>0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3052.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>0.985916</td>\n",
       "      <td>0.208758</td>\n",
       "      <td>0.649306</td>\n",
       "      <td>0.486773</td>\n",
       "      <td>0.112245</td>\n",
       "      <td>0.726667</td>\n",
       "      <td>0.229560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85</td>\n",
       "      <td>10351</td>\n",
       "      <td>3.0</td>\n",
       "      <td>851791395</td>\n",
       "      <td>0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>592.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.040438</td>\n",
       "      <td>0.690972</td>\n",
       "      <td>0.502645</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.713333</td>\n",
       "      <td>0.229560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>588</td>\n",
       "      <td>10351</td>\n",
       "      <td>5.0</td>\n",
       "      <td>851792205</td>\n",
       "      <td>1</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>8980.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>0.929577</td>\n",
       "      <td>0.614369</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.486773</td>\n",
       "      <td>0.224490</td>\n",
       "      <td>0.675555</td>\n",
       "      <td>0.207547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>370</td>\n",
       "      <td>1090</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1117852491</td>\n",
       "      <td>0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3087.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.957747</td>\n",
       "      <td>0.211153</td>\n",
       "      <td>0.482639</td>\n",
       "      <td>0.555555</td>\n",
       "      <td>0.030612</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.204403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  userId  rating   timestamp  label  releaseYear  movieGenre1  \\\n",
       "0      593   10096     4.0   954365552      1       1991.0           13   \n",
       "1      832   10351     3.0   851791379      0       1996.0           13   \n",
       "2       85   10351     3.0   851791395      0       1995.0           11   \n",
       "3      588   10351     5.0   851792205      1       1992.0            3   \n",
       "4      370    1090     2.0  1117852491      0       1994.0            2   \n",
       "\n",
       "   movieGenre2  movieGenre3  movieRatingCount  ...  userGenre3  userGenre4  \\\n",
       "0            4           12           13692.0  ...          17          12   \n",
       "1           12            0            3052.0  ...           5          12   \n",
       "2            5            0             592.0  ...           5          12   \n",
       "3           15           18            8980.0  ...          12           5   \n",
       "4            7            0            3087.0  ...           0           0   \n",
       "\n",
       "   userGenre5  scaledReleaseYear  scaledmovieRatingCount  \\\n",
       "0           0           0.915493                0.936777   \n",
       "1          13           0.985916                0.208758   \n",
       "2          13           0.971831                0.040438   \n",
       "3          13           0.929577                0.614369   \n",
       "4           0           0.957747                0.211153   \n",
       "\n",
       "   scaledmovieAvgRating  scaledmovieRatingStddev  scaleduserRatingCount  \\\n",
       "0              0.906250                 0.449735               0.030612   \n",
       "1              0.649306                 0.486773               0.112245   \n",
       "2              0.690972                 0.502645               0.122449   \n",
       "3              0.729167                 0.486773               0.224490   \n",
       "4              0.482639                 0.555555               0.030612   \n",
       "\n",
       "   scaleduserAvgRating  scaleduserRatingStddev  \n",
       "0             0.688889                0.279874  \n",
       "1             0.726667                0.229560  \n",
       "2             0.713333                0.229560  \n",
       "3             0.675555                0.207547  \n",
       "4             0.200000                0.204403  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns2Keep = ['userId', 'userGenre1', 'userGenre2',  'userGenre3','userGenre4', 'userGenre5', 'scaleduserRatingCount',\n",
    "       'scaleduserAvgRating', 'scaleduserRatingStddev', 'movieId',  'movieGenre1', 'movieGenre2', 'movieGenre3', 'scaledReleaseYear', 'scaledmovieRatingCount', 'scaledmovieAvgRating',\n",
    "       'scaledmovieRatingStddev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_feature = training_df[columns2Keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_label = training_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature = test_df[columns2Keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = test_df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSet and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ModelDataSet(Dataset):\n",
    "    # Retrieve an item in every call\n",
    "    def __init__(self, input_DF, label_DF):\n",
    "        self.df = input_DF.astype(np.float32) # IMPORTANT\n",
    "        self.label = label_DF.astype(np.float32)  # IMPORTANT\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        feature = torch.tensor(self.df.iloc[idx, :])\n",
    "        label = torch.tensor(self.label.iloc[idx])\n",
    "        return {'Feature': feature, 'Label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_dataset = ModelDataSet(training_feature, training_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ModelDataSet(test_feature, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(training_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_col = [0, 1, 2, 3, 4, 5, 9, 10, 11, 12] # column_index of sparse features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_col = [6, 7, 8, 13, 14, 15, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_col_size = [30001, 20, 20, 20, 20, 20, 1001, 20, 20, 20] # number of classes per sparse_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, sparse_col, dense_col, sparse_col_size):\n",
    "        super().__init__()\n",
    "        self.sparse_col = sparse_col\n",
    "        self.dense_col = dense_col\n",
    "        self.sparse_col_size = sparse_col_size\n",
    "        \n",
    "        # For categorical features, we embed the features in dense vectors of dimension of 6 * category cardinality^1/4\n",
    "        embedding_size = list(map(lambda x: int(6 * pow(x, 0.25)), self.sparse_col_size))\n",
    "        \n",
    "        # Create embedding layer for all sparse features\n",
    "        sparse_embedding_list = []\n",
    "        for class_size, embed_size in zip(self.sparse_col_size, embedding_size):\n",
    "            sparse_embedding_list.append(nn.Embedding(class_size, embed_size, scale_grad_by_freq=True))\n",
    "        self.sparse_embedding_layer = nn.ModuleList(sparse_embedding_list)\n",
    "        \n",
    "        # cal total embedding size \n",
    "        total_embedding_size = np.sum(embedding_size) + len(self.dense_col)\n",
    "        \n",
    "        # MLP linear layers\n",
    "        self.linear1 = nn.Linear(total_embedding_size, 128)\n",
    "        self.linear2 = nn.Linear(128, 128)\n",
    "        self.linear3 = nn.Linear(128, 1) # last layer\n",
    "        \n",
    "    def forward(self, feature):\n",
    "        feature = feature.view(-1, 17) # convert to 2D tensor if batch_number == 1\n",
    "        sparse_feature = feature[:, self.sparse_col].to(torch.long) # batch x feature #\n",
    "        dense_feature = feature[:, self.dense_col]\n",
    "        embedding_list = []\n",
    "        for i in range(len(self.sparse_col)):\n",
    "            sparse_feature_input = sparse_feature[:, i] # batch x 1\n",
    "            embedding_layer = self.sparse_embedding_layer[i]\n",
    "            embedding_output = embedding_layer(sparse_feature_input) # batch x 1 x embedding_size\n",
    "            embedding_list.append(embedding_output.squeeze(1)) # batch x embedding_size\n",
    "        embedding = torch.cat(embedding_list, dim=1) # batch x sum(embedding_size)\n",
    "        embedding = torch.cat([embedding, dense_feature], dim=1) # batch x (sum(embedding_size)+dense_feature_size)\n",
    "        output = F.relu(self.linear1(embedding)) # batch x 128\n",
    "        output = F.relu(self.linear2(output)) # batch x 128\n",
    "        output = F.sigmoid(self.linear3(output)) # batch x 1\n",
    "        return output.view(-1) # batch\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(sparse_col, dense_col,  sparse_col_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_Eval():\n",
    "    def __init__(self, model, loss_fn, optim, device, train_dataloader, test_dataloader):\n",
    "        self.device = device\n",
    "        self.model = model.to(self.device)\n",
    "        self.optim = optim\n",
    "        self.loss_fn = loss_fn\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.test_dataloader = test_dataloader\n",
    "        self.threashold = 0.5 # threashold for positive class\n",
    "        \n",
    "    def train(self, epochs):\n",
    "        self.model.train()\n",
    "        for epoch in range(epochs):\n",
    "            print(\"==========================================================\")\n",
    "            print(\"start training epoch: {}\".format(epoch+1))\n",
    "            loss_list = []\n",
    "            pred_list = []\n",
    "            label_list = []\n",
    "            \n",
    "            iteration = 1\n",
    "            for train_data in self.train_dataloader:\n",
    "                feature = train_data['Feature'].to(self.device)\n",
    "                label = train_data['Label'].to(self.device)\n",
    "                prediction = self.model(feature)\n",
    "                \n",
    "                pred_list.extend(prediction.tolist())\n",
    "                label_list.extend(label.tolist())\n",
    "                \n",
    "                cur_loss = self.loss_fn(prediction, label)\n",
    "                loss_list.append(cur_loss.item())\n",
    "                cur_loss.backward()\n",
    "                self.optim.step()\n",
    "                self.optim.zero_grad()\n",
    "                \n",
    "                # logging every 20 iteration\n",
    "                if iteration % 20 == 0:\n",
    "                    print(\"---------------------------------------------------------\")\n",
    "                    print(\"epoch {}/{}, cur_iteration is {}, logloss is {:.2f}\"\n",
    "                          .format(epoch+1, epochs, iteration, cur_loss.item()))\n",
    "                iteration += 1\n",
    "                \n",
    "            # validation every epoch\n",
    "            training_loss, training_accuracy, training_roc_score = self._getMetric(loss_list, pred_list, label_list)\n",
    "            print(\"==========================================================\")\n",
    "            print(\"Result of epoch {}\".format(epoch+1))\n",
    "            print(f\"training loss: {training_loss:.2f}, accuracy: {training_accuracy:.3f}, roc_score: {training_roc_score:.2f}\")\n",
    "            \n",
    "            test_loss, test_accuracy, test_roc_score = self.eval()\n",
    "            print(f\"test loss: {test_loss:.2f}, accuracy: {test_accuracy:.3f}, roc_score: {test_roc_score:.2f}\")\n",
    "            # summary.add_embedding(np.reshape(np.array(loss_list), (1, -1)), tag=\"loss_list\")\n",
    "            # summary.add_embedding(np.reshape(np.array(pred_list), (1, -1)), tag=\"pred_list\")\n",
    "            # summary.add_embedding(np.reshape(np.array(label_list), (1, -1)), tag=\"label_list\")\n",
    "            # summary.add_scalar(\"training_loss\", training_loss)\n",
    "            # summary.add_scalar(\"training_accuracy\", training_accuracy)\n",
    "            # summary.add_scalar(\"training_roc_score\", training_roc_score)\n",
    "    \n",
    "    def eval(self):\n",
    "        # return logloss, accuracy, roc_score\n",
    "        self.model.eval()\n",
    "        loss_list = []\n",
    "        pred_list = []\n",
    "        label_list = []\n",
    "        with torch.no_grad():\n",
    "            for test_data in self.test_dataloader:\n",
    "                feature = test_data['Feature'].to(self.device)\n",
    "                label = test_data['Label'].to(self.device)\n",
    "                prediction = self.model(feature)\n",
    "                cur_loss = self.loss_fn(prediction, label)\n",
    "                \n",
    "                loss_list.append(cur_loss.item())\n",
    "                pred_list.extend(prediction.tolist())\n",
    "                label_list.extend(label.tolist())\n",
    "        return self._getMetric(loss_list, pred_list, label_list)\n",
    "                \n",
    "    def _getMetric(self, loss_list, pred_list, label_list):\n",
    "        # return logloss, accuracy, roc_score        \n",
    "        # average logloss\n",
    "        avg_loss = np.mean(loss_list)\n",
    "        # roc_score\n",
    "        roc_score = roc_auc_score(label_list, pred_list)\n",
    "        # average accuracy\n",
    "        pred_class_list = list(map(lambda x: 1 if x >= self.threashold else 0, pred_list))\n",
    "        correct_count = 0\n",
    "        for p, l in zip(pred_class_list, label_list):\n",
    "            if p == l:\n",
    "                correct_count += 1\n",
    "        avg_accuracy = correct_count / len(label_list)\n",
    "        \n",
    "        return avg_loss, avg_accuracy, roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eval = Train_Eval(model, loss_fn, optimizer, dev, training_dataloader, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "start training epoch: 1\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 20, logloss is 0.70\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 40, logloss is 0.68\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 60, logloss is 0.70\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 80, logloss is 0.67\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 100, logloss is 0.63\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 120, logloss is 0.64\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 140, logloss is 0.63\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 160, logloss is 0.66\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 180, logloss is 0.64\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 200, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 220, logloss is 0.66\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 240, logloss is 0.61\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 260, logloss is 0.64\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 280, logloss is 0.67\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 300, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 320, logloss is 0.61\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 340, logloss is 0.65\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 360, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 380, logloss is 0.61\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 400, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 420, logloss is 0.54\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 440, logloss is 0.63\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 460, logloss is 0.64\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 480, logloss is 0.64\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 500, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 520, logloss is 0.67\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 540, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 560, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 580, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 600, logloss is 0.65\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 620, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 640, logloss is 0.64\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 660, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 680, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 700, logloss is 0.64\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 720, logloss is 0.67\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 740, logloss is 0.66\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 760, logloss is 0.63\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 780, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 800, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 820, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 840, logloss is 0.69\n",
      "==========================================================\n",
      "Result of epoch 1\n",
      "training loss: 0.63, accuracy: 0.640, roc_score: 0.70\n",
      "test loss: 0.57, accuracy: 0.711, roc_score: 0.75\n",
      "==========================================================\n",
      "start training epoch: 2\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 20, logloss is 0.54\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 40, logloss is 0.55\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 60, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 80, logloss is 0.52\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 100, logloss is 0.53\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 120, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 140, logloss is 0.54\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 160, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 180, logloss is 0.61\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 200, logloss is 0.61\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 220, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 240, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 260, logloss is 0.54\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 280, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 300, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 320, logloss is 0.52\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 340, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 360, logloss is 0.64\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 380, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 400, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 420, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 440, logloss is 0.64\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 460, logloss is 0.53\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 480, logloss is 0.49\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 500, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 520, logloss is 0.50\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 540, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 560, logloss is 0.51\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 580, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 600, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 620, logloss is 0.49\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 640, logloss is 0.52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 660, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 680, logloss is 0.65\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 700, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 720, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 740, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 760, logloss is 0.61\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 780, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 800, logloss is 0.54\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 820, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 840, logloss is 0.60\n",
      "==========================================================\n",
      "Result of epoch 2\n",
      "training loss: 0.58, accuracy: 0.698, roc_score: 0.76\n",
      "test loss: 0.56, accuracy: 0.716, roc_score: 0.75\n",
      "==========================================================\n",
      "start training epoch: 3\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 20, logloss is 0.52\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 40, logloss is 0.50\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 60, logloss is 0.52\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 80, logloss is 0.53\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 100, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 120, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 140, logloss is 0.50\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 160, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 180, logloss is 0.51\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 200, logloss is 0.47\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 220, logloss is 0.50\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 240, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 260, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 280, logloss is 0.53\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 300, logloss is 0.49\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 320, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 340, logloss is 0.61\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 360, logloss is 0.47\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 380, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 400, logloss is 0.47\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 420, logloss is 0.42\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 440, logloss is 0.48\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 460, logloss is 0.52\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 480, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 500, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 520, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 540, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 560, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 580, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 600, logloss is 0.61\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 620, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 640, logloss is 0.52\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 660, logloss is 0.51\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 680, logloss is 0.53\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 700, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 720, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 740, logloss is 0.45\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 760, logloss is 0.47\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 780, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 800, logloss is 0.52\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 820, logloss is 0.47\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 840, logloss is 0.59\n",
      "==========================================================\n",
      "Result of epoch 3\n",
      "training loss: 0.53, accuracy: 0.731, roc_score: 0.80\n",
      "test loss: 0.57, accuracy: 0.711, roc_score: 0.75\n",
      "==========================================================\n",
      "start training epoch: 4\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 20, logloss is 0.47\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 40, logloss is 0.40\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 60, logloss is 0.42\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 80, logloss is 0.51\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 100, logloss is 0.44\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 120, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 140, logloss is 0.54\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 160, logloss is 0.49\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 180, logloss is 0.49\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 200, logloss is 0.46\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 220, logloss is 0.55\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 240, logloss is 0.45\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 260, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 280, logloss is 0.53\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 300, logloss is 0.55\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 320, logloss is 0.53\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 340, logloss is 0.45\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 360, logloss is 0.52\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 380, logloss is 0.52\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 400, logloss is 0.60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 420, logloss is 0.51\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 440, logloss is 0.47\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 460, logloss is 0.47\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 480, logloss is 0.55\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 500, logloss is 0.48\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 520, logloss is 0.48\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 540, logloss is 0.52\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 560, logloss is 0.45\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 580, logloss is 0.55\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 600, logloss is 0.44\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 620, logloss is 0.45\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 640, logloss is 0.41\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 660, logloss is 0.50\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 680, logloss is 0.44\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 700, logloss is 0.53\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 720, logloss is 0.52\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 740, logloss is 0.47\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 760, logloss is 0.46\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 780, logloss is 0.55\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 800, logloss is 0.50\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 820, logloss is 0.43\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 840, logloss is 0.52\n",
      "==========================================================\n",
      "Result of epoch 4\n",
      "training loss: 0.49, accuracy: 0.763, roc_score: 0.84\n",
      "test loss: 0.61, accuracy: 0.703, roc_score: 0.74\n",
      "==========================================================\n",
      "start training epoch: 5\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 20, logloss is 0.51\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 40, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 60, logloss is 0.42\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 80, logloss is 0.46\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 100, logloss is 0.52\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 120, logloss is 0.42\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 140, logloss is 0.43\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 160, logloss is 0.49\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 180, logloss is 0.47\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 200, logloss is 0.48\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 220, logloss is 0.40\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 240, logloss is 0.39\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 260, logloss is 0.47\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 280, logloss is 0.39\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 300, logloss is 0.44\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 320, logloss is 0.43\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 340, logloss is 0.36\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 360, logloss is 0.42\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 380, logloss is 0.44\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 400, logloss is 0.46\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 420, logloss is 0.44\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 440, logloss is 0.51\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 460, logloss is 0.38\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 480, logloss is 0.50\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 500, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 520, logloss is 0.36\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 540, logloss is 0.42\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 560, logloss is 0.41\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 580, logloss is 0.51\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 600, logloss is 0.49\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 620, logloss is 0.44\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 640, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 660, logloss is 0.64\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 680, logloss is 0.47\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 700, logloss is 0.49\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 720, logloss is 0.50\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 740, logloss is 0.47\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 760, logloss is 0.43\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 780, logloss is 0.41\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 800, logloss is 0.43\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 820, logloss is 0.39\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 840, logloss is 0.42\n",
      "==========================================================\n",
      "Result of epoch 5\n",
      "training loss: 0.44, accuracy: 0.794, roc_score: 0.88\n",
      "test loss: 0.66, accuracy: 0.683, roc_score: 0.73\n"
     ]
    }
   ],
   "source": [
    "train_eval.train(EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
